plot(Education, reg_simple3$fitted.values, col = "blue", ylab = "Fitted Values", main = "Comparison of Value Fit for Polynomial Regression")
points(Education, reg_simple2$fitted.values, col = "black")
lines(Education, reg_simple$fitted.values, col = "red") # the small deviations of fit indicates that the linear model is sufficient to use
bandwidth <- npregbw(Fertility ~ Education)
summary(bandwidth) # the optimal bandwidth is 6.76351
# We then estimate the function using the optimal bandwidth #
npreg1 <- npreg(bws = bandwidth)
# We plot the results and add the linear regression to it #
plot(bandwith, plot.errors.method = "bootstrap", main = "Non-parametric regression")
lines(Education, simple_linear$fitted.values, col = "red")
## Additionally, we want to inspect the different fits visually ##
plot(Education, reg_simple3$fitted.values, col = "blue", ylab = "Fitted Values", main = "Comparison of Value Fit for Polynomial Regression")
points(Education, reg_simple2$fitted.values, col = "black")
lines(Education, reg_simple$fitted.values, col = "red") # the small deviations of fit indicates that the linear model is sufficient to use
resettest(reg_woEx, power = 2:3, type = "regressor") # p-value of 61.2% suggests that adding second and third order of the regressor makes no statistically significant contribution to the model
reg_full = lm(Fertility ~ Education + Agriculture + Examination + Catholic + Infant.Mortality, data = mydata)
summary(reg_full) # Education is still highly significant from a statistical standpoint, however Examination does not seem to have a significant influence on Fertility
ols_plot_obs_fit(reg_full) # The model seems to fit pretty well based on this visual inspection
ols_vif_tol(reg_full) # Based on the given values which are all below threshold of 4 / 5 and especially 10, there does not seem to be a problem with multicollinearity in the model
step1 <- lm(Fertility ~ 1, data = mydata) # using only the intercept
step2 <- lm(Fertility ~ ., data = mydata) # running the full regression
# Next, we run the forward and backward regression #
step(step1, direction = "forward", scope = list(lower = step1, upper = step2))
step(step2, direction = "backward") # Both methods yield the same result: the best model does not include the variable "Examination"
# We then plot the results for better visual inspection #
model_eva <- leaps::regsubsets(Fertility ~ ., nbest = 2) # number of best models per number of included variables
print(summary(model_eva))
print(summary(model_eva)$which) # it seems to become evident that including both variables Education and Examination decreases the goodness of the model
# We can further visualize the BIC factor and AdjR2
par(mfrow = c(1, 2))
plot(model_eva, main ="Comparison of goodness of different models") #the lower the BIC, the better the model. The  best model includes Agriculture, Education, Catholic and Infant.Mortality
plot(model_eva, scale = "adjr2") # The highest and second highest adj. R2 are achieved by the full model and by excluding Examination
reg_woEx = lm(Fertility ~ Education + Agriculture + Catholic + Infant.Mortality, data = mydata)
summary(reg_woEx)
ols_plot_obs_fit(reg_woEx) # again, the fit seems to be pretty well
# We run a reduced model diagnostics, not expecting any different results from before #
ols_plot_diagnostics(reg_woEx) # The residuals seem to be normally distributed and no heteroskedasticity present
mydata[cooks.distance(reg_woEx) > 0.1,] # Only Porrentruy, Sierre and Rive Gauche are now influential points according to the Cook's Distance parameter
# We run the Shapiro-Wilk and Breusch-Pagan test #
resi_woEx = reg_woEx$residuals
shapiro.test(resi_woEx) # large p value, therefore normal distribution of residuals
bptest(reg_woEx) # high p value, therefore no heteroskedasticity
# We check once more for multicollinearity between the variables #
ols_vif_tol(reg_woEx) # Unsurprisingly, there is no multicollinearity here either
# Lastly, we run a Ramsey RESET test for functional form #
resettest(reg_woEx, power = 2:3, type = "regressor") # p-value of 0.6311 suggests that adding second and third order of the regressor makes no statistically significant contribution to the model
library(datasets.load)
library(tidyverse)
library(ggplot2)
library(dplyr)
library(lattice)
library(plotly)
library(knitr)
library(MASS)
library(faraway)
library(moments)
library(stargazer)
library(leaps)
library(glmnet)
library(np)
library(lmtest)
library(mctest)
library(faraway)
library(lattice)
library(olsrr)
library(corrplot)
library(GGally)
help(swiss)
View(swiss)
mydata = swiss[, 1:6]
View(mydata)
attach(mydata)
install.packages("ggcorrplot")
library(ggcorrplot)
levelplot(cor(mydata), xlab = "", ylab = "") # visible correlation between Fertility and Education & Examination. Also, highly negative correlation between Education and Agriculture (Instrumental Variable?)
ggcorrplot(cor_matrix, hc.order = TRUE,
type = "lower",
lab = TRUE,
lab_size = 3,
method = "circle",
colors = c("tomato2", "white", "springgreen3"),
title = "Correlogram Swiss Data Set",
ggtheme = theme_bw)
ggcorrplot(cor_matrix, hc.order = TRUE,
lab = TRUE,
lab_size = 3,
method = "circle",
colors = c("tomato2", "white", "springgreen3"),
title = "Correlogram Swiss Data Set",
ggtheme = theme_bw)
ggcorrplot(cor(mydata), hc.order = TRUE,
lab = TRUE,
lab_size = 3,
method = "circle",
colors = c("tomato2", "white", "springgreen3"),
title = "Correlogram Swiss Data Set",
ggtheme = theme_bw)
ggcorrplot(cor(mydata), hc.order = TRUE,
type = "lower",
lab = TRUE,
lab_size = 7,
method = "circle",
colors = c("tomato2", "white", "springgreen3"),
title = "Correlogram Swiss Data Set",
ggtheme = theme_bw)
ggcorrplot(cor(mydata), hc.order = TRUE,
type = "lower",
lab = TRUE,
lab_size = 3,
method = "circle",
colors = c("tomato2", "white", "springgreen3"),
title = "Correlogram Swiss Data Set",
ggtheme = theme_bw)
ggcorrplot(cor(mydata), hc.order = TRUE,
type = "lower",
lab = TRUE,
lab_size = 3,
method = "square",
colors = c("tomato2", "white", "springgreen3"),
title = "Correlogram Swiss Data Set",
ggtheme = theme_bw)
ggcorrplot(cor(mydata), hc.order = TRUE,
type = "lower",
lab = TRUE,
lab_size = 5,
method = "square",
colors = c("tomato2", "white", "springgreen3"),
title = "Correlogram Swiss Data Set",
ggtheme = theme_bw)
ggcorrplot(cor(mydata), hc.order = TRUE,
type = "lower",
digits = 3,
lab = TRUE,
lab_size = 5,
method = "square",
colors = c("tomato2", "white", "springgreen3"),
title = "Correlogram Swiss Data Set",
ggtheme = theme_bw)
ggcorrplot(cor(mydata), hc.order = TRUE,
type = "upper",
digits = 3,
lab = TRUE,
lab_size = 5,
method = "square",
colors = c("tomato2", "white", "springgreen3"),
title = "Correlogram Swiss Data Set",
ggtheme = theme_bw)
ggcorrplot(cor(mydata), hc.order = TRUE,
type = "lower",
digits = 3,
lab = TRUE,
lab_size = 5,
method = "square",
colors = c("tomato2", "white", "springgreen3"),
title = "Correlogram Swiss Data Set",
ggtheme = theme_bw)
levelplot(cor(mydata), xlab = "", ylab = "") # visible correlation between Fertility and Education & Examination. Also, highly negative correlation between Education and Agriculture (Instrumental Variable?)
levelplot(cor(mydata),
xlab = "",
ylab = "",
type = "lower") # visible correlation between Fertility and Education & Examination. Also, highly negative correlation between Education and Agriculture (Instrumental Variable?)
levelplot(cor(mydata),
xlab = "",
ylab = "") # visible correlation between Fertility and Education & Examination. Also, highly negative correlation between Education and Agriculture (Instrumental Variable?)
ggcorrplot(cor(mydata), hc.order = TRUE,
type = "lower",
digits = 3,
lab = TRUE,
lab_size = 5,
method = "square",
colors = c("tomato2", "white", "springgreen3"),
title = "Correlogram Swiss Data Set",
ggtheme = theme_bw)
ggplot(mydata) + geom_violin()
ggplot(mydata, aes(Fertility, Education)) + geom_violin()
ggplot(mydata, aes(c(Agriculture, Examination, Education, Catholic, Infant.Mortality), Fertility)) + geom_violin()
boxplot(mydata, ylab = "Frequency", main = "Boxplot of the Swiss Fertility data set") # Comment: We have to watch out with "Catholic" as it is more or less a "binary" variable
mydata %>%
ggplot() + geom_boxplot()
ggplot(mydata, aes(mydata))
boxplot(mydata, ylab = "Frequency", main = "Boxplot of the Swiss Fertility data set") # Comment: We have to watch out with "Catholic" as it is more or less a "binary" variable
ggplot(mydata, aes(Education, Fertility)) + geom_boxplot() +
geom_dotplot(binaxis = "y", stackdir = "center", dotsize = 1)
boxplot(mydata, ylab = "Frequency", main = "Boxplot of the Swiss Fertility data set") # Comment: We have to watch out with "Catholic" as it is more or less a "binary" variable
dotplot(mydata)
boxplot(mydata, ylab = "Frequency", main = "Boxplot of the Swiss Fertility data set") # Comment: We have to watch out with "Catholic" as it is more or less a "binary" variable
ggcorrplot(cor(mydata), hc.order = TRUE, # another way of visualizing the correlation matrix
type = "lower",
digits = 3,
lab = TRUE,
lab_size = 5,
method = "square",
colors = c("tomato2", "white", "springgreen3"),
title = "Correlogram Swiss Data Set",
ggtheme = theme_bw)
ggpairs(mydata)
hist(Fertility, main = "Fertility", xlab = "Fertility") # Fertility rates are mostly between 60 and 90%
boxplot(mydata, ylab = "Frequency", main = "Boxplot of the Swiss Fertility data set")
reg_full = lm(Fertility ~ Education + Agriculture + Examination + Catholic + Infant.Mortality, data = mydata)
summary(reg_full) # Education is still highly significant from a statistical standpoint, however Examination does not seem to have a significant influence on Fertility
boxcox(reg_simple, data = mydata, lambda = seq(from = -3, to = 3, length = 50))
boxcox(reg_simple, data = mydata, lambda = seq(from = -2, to = 2, length = 50))
boxcox(reg_simple, data = mydata, lambda = seq(from = -3, to = 3, length = 50))
boxcox(reg_simple, data = mydata, lambda = seq(from = -2, to = 2, length = 50))
plot(reg_simple)
best_lambda
boxcox(reg_simple, data = mydata, lambda = seq(from = -2, to = 2, length = 50))
reg_simple_transformed = lm(log(Fertility) ~ Education, data = mydata)
summary(reg_simple_transformed)
plot(reg_simple_transformed)
resi_simple = reg_simple$residuals
plot(mydata$Education, resi_simple, main = "Residuals from the linear regression (Fertility ~ Education)", xlab = "Education", ylab = "Residuals")
lines(mydata$Education, rep(0, times = length(mydata$Education)), col = 2) # no clear pattern can be observed in the residuals (can only be said for lower levels of Education given amount of datapoints)
qqnorm(resi_simple)
qqline(resi_simple)
plot(density(resi_simple), main = "Residuals for the Simple Linear Regression Model")
shapiro.test(resi_simple) # p-value of 0.0592 so we cannot reject the 0 hypothesis of normal distribution
bptest(reg_simple) #p-value of 0.5252
reg_simple = lm(Fertility ~ Education, data = mydata)
summary(reg_simple)
reg_simple_transformed = lm(log(Fertility) ~ Education, data = mydata)
summary(reg_simple_transformed)
plot(Education, Fertility)
abline(reg_simple_transformed)
plot(Education, Fertility)
abline(reg_simple_transformed)
corrplot(cor(mydata), method = "color")
ggplot(mydata, aes(log1p(Education), Fertility)) +
geom_point() +
geom_smooth(method = "loess", se = FALSE)
lm_log.model = lm(Fertility~ log1p(Education), data = mydata)
summary(lm_log.model)
ggplot(mydata, aes(Education, log(Fertility)) +
geom_point() +
geom_smooth(method = "loess", se = FALSE)
ggplot(mydata, aes(Education, log(Fertility)) +
geom_point() +
geom_smooth(method = "lm", se = FALSE)
mydata %>%
ggplot() +
geom_point(mapping = aes(x = Infant.Mortality, y = Fertility)) +
geom_smooth(mapping = aes(x = Infant.Mortality, y = Fertility),
method = "lm")
lm_log.model = lm(Fertility~ log1p(Education), data = mydata)
summary(lm_log.model)
ggplot(mydata, aes(log1p(Education), Fertility)) +
geom_point() +
geom_smooth(method = "loess", se = FALSE)
reg_simple_transformed = lm(ln(Fertility) ~ Education, data = mydata)
summary(reg_simple_transformed)
plot(reg_simple_transformed)
ols_plot_diagnostics(reg_simple)
ols_plot_diagnostics(reg_simple_transformed)
hist(ln(Fertility))
hist(log(Fertility))
hist(Fertility)
reg_simple_transformed_2 = lm(Fertility ~ ln(Education), data = mydata)
summary(reg_simple_transformed_2)
reg_simple_transformed_2 = lm(Fertility ~ ln(Education), data = mydata)
reg_simple_transformed = lm(ln(Fertility) ~ Education, data = mydata)
summary(reg_simple_transformed)
reg_simple_transformed_2 = lm(Fertility ~ log(Education), data = mydata)
summary(reg_simple_transformed_2)
reg_simple_transformed_2 = lm(Fertility ~ log(Education), data = mydata)
summary(reg_simple_transformed_2)
boxcox(reg_woEx)
best_lambda
boxcox(reg_simple, data = mydata, lambda = seq(from = -2, to = 2, length = 50))
best_lambda # given the best lambda is close to zero, we transform the dependent variable using the log function
boxcox(reg_woEx) # The model seems to be accurately approximated, no need for transformation visible
ggplot(mydata, aes(log1p(Education), Fertility)) +
geom_point() +
geom_smooth(method = "loess", se = FALSE)
ols_plot_obs_fit(reg_simple) # The fit does not seem completely off, but could be further improved
plot(Education, log(Fertility))
line(reg_simple_transformed)
plot(Education, log(Fertility))
mydata %>%
ggplot() +
xlab("Education") +
ylab("Fertility") +
geom_point(mapping = aes(
x = Education,
y = log(Fertility),
color = Education,
size = Fertility,
alpha = 0.5)) +
geom_smooth(mapping = aes(
x = Education,
y = Fertility),
method = "lm") +
ylim(0, 100)
mydata %>%
ggplot() +
xlab("Education") +
ylab("Fertility") +
geom_point(mapping = aes(
x = Education,
y = Fertility,
color = Education,
size = Fertility,
alpha = 0.5)) +
geom_smooth(mapping = aes(
x = Education,
y = Fertility),
method = "lm") +
ylim(0, 100)
Robust_Regression = rlm(Fertility ~ Education, data = mydata)
summary(Robust_Regression)
summary(reg_simple)
boxcox(reg_simple, data = mydata, lambda = seq(from = -2, to = 2, length = 50))
best_lambda # given the best lambda is close to zero, we transform the dependent variable using the log function
reg_simple_transformed = lm(log(Fertility) ~ Education, data = mydata)
summary(reg_simple_transformed)
reg_simple = lm(Fertility ~ Education, data = mydata)
summary(reg_simple)
ols_plot_diagnostics(reg_simple_transformed)
plot(reg_simple_transformed)
plot(Education, log(Fertility))
abline(reg_simple_transformed)
#
mydata %>%
ggplot() +
geom_point(mapping = aes(x = Education, y = Fertility)) +
geom_smooth(mapping = aes(x = Education, y = Fertility),
method = "lm") +
ylim(0, 100)
reg_simple_transformed_2 = lm(Fertility ~ log(Education), data = mydata)
summary(reg_simple_transformed_2)
boxcox(reg_woEx) # The model seems to be accurately approximated, no need for transformation visible
stargazer(reg_simple, reg_simple_transformed, reg_simple2, reg_simple3, reg_full, reg_woEx, reg_simple_Dummy, reg_woEx_Dummy,
type = "html",
out = "RegressionTable.html",
digits = 3,
header = FALSE,
align = TRUE,
no.space = TRUE,
title = "Regression Analysis of Education on Fertility",
intercept.bottom = FALSE,
dep.var.caption = "Impact on Fertility (in %)",
dep.var.labels.include = FALSE,
covariate.labels = c("Constant", "Education", "Education<sup>2</sup>", "Education<sup>3</sup>", "Agriculture", "Examination", "Catholic", "Infant.Mortality", "CatholicDummy"),
column.labels = c("Simple", "Multivariate"),
column.separate = c(3, 4),
add.lines = list(c("Model", "Linear", "Quadratic", "Cubic", "Full", "w/o Exam.", "Dummy", "Dummy Full")),
notes = "SE provided in parantheses",
results = "asis")
library(datasets.load)
library(tidyverse)
library(ggplot2)
library(dplyr)
library(lattice)
library(plotly)
library(knitr)
library(MASS)
library(faraway)
library(moments)
library(stargazer)
library(leaps)
library(glmnet)
library(np)
library(lmtest)
library(mctest)
library(faraway)
library(lattice)
library(olsrr)
library(corrplot)
library(GGally)
library(ggcorrplot)
help(swiss)
View(swiss)
mydata = swiss[, 1:6]
View(mydata)
attach(mydata)
reg_simple = lm(Fertility ~ Education, data = mydata)
summary(reg_simple)
boxcox(reg_simple, data = mydata, lambda = seq(from = -2, to = 2, length = 50))
reg_simple_transformed = lm(log(Fertility) ~ Education, data = mydata)
summary(reg_simple_transformed)
plot(reg_simple_transformed)
reg_simple_transformed_2 = lm(Fertility ~ log(Education), data = mydata)
summary(reg_simple_transformed_2) # no improvement, therefore no log transformation of independent variable needed
Education2 = Education^2
Education3 = Education^3
reg_simple2 <- lm(Fertility ~ Education + Education2)
reg_simple3 <- lm(Fertility ~ Education + Education2 + Education3)
summary(reg_simple2) # the very large p-values do not indicate a statistically significant impact of Education on Fertility for any power
summary(reg_simple3) # the very large p-values do not indicate a statistically significant impact of Education on Fertility for any power
reg_full = lm(Fertility ~ Education + Agriculture + Examination + Catholic + Infant.Mortality, data = mydata)
summary(reg_full) # Education is still highly significant from a statistical standpoint, however Examination does not seem to have a significant influence on Fertility
reg_woEx = lm(Fertility ~ Education + Agriculture + Catholic + Infant.Mortality, data = mydata)
summary(reg_woEx)
swiss$CatholicDummy = ifelse(swiss$Catholic >= 50, 1, 0)
View(swiss)
reg_simple_Dummy = lm(Fertility ~ Education + CatholicDummy, data = swiss)
summary(reg_simple_Dummy)
reg_woEx_Dummy = lm(Fertility ~ Agriculture + Education + Infant.Mortality + CatholicDummy, data = swiss)
summary(reg_woEx_Dummy)
stargazer(reg_simple, reg_simple_transformed, reg_simple2, reg_simple3, reg_full, reg_woEx, reg_simple_Dummy, reg_woEx_Dummy,
type = "html",
out = "RegressionTable.html",
digits = 3,
header = FALSE,
align = TRUE,
no.space = TRUE,
title = "Regression Analysis of Education on Fertility",
intercept.bottom = FALSE,
dep.var.caption = "Impact on Fertility (in %)",
dep.var.labels.include = FALSE,
covariate.labels = c("Constant", "Education", "Education<sup>2</sup>", "Education<sup>3</sup>", "Agriculture", "Examination", "Catholic", "Infant.Mortality", "CatholicDummy"),
column.labels = c("Simple", "Multivariate"),
column.separate = c(3, 4),
add.lines = list(c("Model", "Linear", "Quadratic", "Cubic", "Full", "w/o Exam.", "Dummy", "Dummy Full")),
notes = "SE provided in parantheses",
results = "asis")
stargazer(reg_simple, reg_simple_transformed, reg_simple2, reg_simple3, reg_full, reg_woEx, reg_simple_Dummy, reg_woEx_Dummy,
type = "html",
out = "RegressionTable.html",
digits = 3,
header = FALSE,
align = TRUE,
no.space = TRUE,
title = "Regression Analysis of Education on Fertility",
intercept.bottom = FALSE,
dep.var.caption = "Impact on Fertility (in %)",
dep.var.labels.include = FALSE,
covariate.labels = c("Constant", "Education", "Education<sup>2</sup>", "Education<sup>3</sup>", "Agriculture", "Examination", "Catholic", "Infant.Mortality", "CatholicDummy"),
column.labels = c("Simple", "Multivariate"),
column.separate = c(2, 6),
add.lines = list(c("Model", "Linear", "Log Y", "Quadratic", "Cubic", "Full", "w/o Exam.", "Dummy", "Dummy Full")),
notes = "SE provided in parantheses",
results = "asis")
stargazer(reg_simple, reg_simple_transformed, reg_simple2, reg_simple3, reg_full, reg_woEx,
type = "html",
out = "RegressionTableShort.html",
digits = 3,
header = FALSE,
align = TRUE,
no.space = TRUE,
title = "Regression Analysis of Education on Fertility",
intercept.bottom = FALSE,
dep.var.caption = "Impact on Fertility (in %)",
dep.var.labels.include = FALSE,
covariate.labels = c("Constant", "Education", "Education<sup>2</sup>", "Education<sup>3</sup>", "Agriculture", "Examination", "Catholic", "Infant.Mortality"),
column.labels = c("Simple", "Multivariate"),
column.separate = c(2, 4),
add.lines = list(c("Model", "Linear", "Log Y", "Quadratic", "Cubic", "Full", "w/o Exam.")),
omit.stat = c("rsq", "f", "ser"),
notes = "SE provided in parantheses",
results = "asis")
ggcorrplot(cor(mydata), hc.order = TRUE, # another way of visualizing the correlation matrix
type = "lower",
digits = 3,
lab = TRUE,
lab_size = 5,
method = "square",
colors = c("tomato2", "white", "springgreen3"),
title = "Correlogram Swiss Data Set",
ggtheme = theme_bw)
pairs(mydata, upper.panel = NULL, pch = 20, cex = 1.25) # assumption: linear relationship between Education and Examination/Examination and Agriculture
stargazer(reg_simple, reg_simple_transformed, reg_simple2, reg_simple3, reg_full, reg_woEx,
type = "html",
out = "RegressionTableShort.html",
digits = 3,
header = FALSE,
align = TRUE,
no.space = TRUE,
title = "Regression Analysis of Education on Fertility",
intercept.bottom = FALSE,
dep.var.caption = "Impact on Fertility",
dep.var.labels.include = FALSE,
covariate.labels = c("Constant", "Education", "Education<sup>2</sup>", "Education<sup>3</sup>", "Agriculture", "Examination", "Catholic", "Infant.Mortality"),
column.labels = c("Simple", "Multivariate"),
column.separate = c(2, 4),
add.lines = list(c("Model", "Linear", "Log Y", "Quadratic", "Cubic", "Full", "w/o Exam.")),
omit.stat = c("rsq", "f", "ser"),
notes = "SE provided in parantheses",
results = "asis")
plot(density(Fertility), main = "Fertility")
plot(density(Fertility), main = "Fertility")
rug(Fertility)
hist(Fertility, freq = f, add = T)
abline(v=c(mean(Fertility), median(Fertility)), col="gray94") # Median and Mean close, almost normally distributed with some tail
plot(density(Fertility), main = "Fertility")
hist(Fertility, freq = f, add = T)
abline(v=c(mean(Fertility), median(Fertility)), col="gray94") # Median and Mean close, almost normally distributed with some tail
plot(density(Fertility), main = "Fertility")
abline(v=c(mean(Fertility), median(Fertility)), col="gray94") # Median and Mean close, almost normally distributed with some tail
hist(Fertility, main = "Fertility", xlab = "Fertility")
lines(density(Fertility))
hist(Fertility, main = "Fertility", xlab = "Fertility") # Fertility rates are mostly between 60 and 90%
hist(Education, main = "Education", xlab = "Education") # Mostly lower levels of education in the dataset
plot.ecdf(Fertility, xlab = "Fertility", main = "Empirical Distribution Function Fertility")
plot.ecdf(Agriculture, xlab = "Agriculture", main ="Empirical Distribution Function Agriculture")
plot.ecdf(Examination, xlab = "Examination", main = "Empirical Distribution Function Examination")
plot.ecdf(Catholic, xlab = "Catholic", main = "Empirical Distribution Function Catholic") # Comment: looks almost binary
plot.ecdf(Infant.Mortality, xlab = "Infant.Mortality", main = "Empirical Distribution Function Infant Mortality")
plot(density(Fertility), main = "Fertility")
abline(v=c(mean(Fertility), median(Fertility)), col="gray94") # Median and Mean close, almost normally distributed with some tail
hist(Fertility, main = "Fertility", xlab = "Fertility")
lines(density(Fertility))
Catholic2 = Catholic^2
Catholic2
reg_woEx_2 = lm(Fertility ~ Education + Agriculture + Catholic + Catholic2 + Infant.Mortality, data = mydata)
summary(reg_woEx_2)
Catholic2 = Catholic^2
Catholic3 = Catholic^3
reg_woEx_2 = lm(Fertility ~ Education + Agriculture + Catholic + Catholic2 + Catholic3 + Infant.Mortality, data = mydata)
summary(reg_woEx_2)
Interaction = lm(Fertility ~ Education + Agriculture + Catholic + Infant.Mortality + Education:Catholic, data = mydata)
Interaction = lm(Fertility ~ Education + Agriculture + Catholic + Infant.Mortality + Education:Catholic, data = mydata)
summary(Interaction)
